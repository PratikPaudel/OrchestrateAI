# File: backend/app/agents/reviewer.py
import os
from pydantic import BaseModel, Field
from typing import List
import re
from ..core.multi_llm import multi_llm_client
import logging

logger = logging.getLogger("orchestrateai.agent.reviewer")

class Review(BaseModel):
    """A structured review of a summary's reliability and content."""
    critique: str = Field(description="Constructive critique of the summary, noting any bias or logical fallacies.")
    is_reliable: bool = Field(description="A boolean flag indicating if the source appears reliable.")
    verified_claims: List[str] = Field(description="A list of key claims from the summary that were checked.")

class ReviewerAgent:
    def __init__(self):
        # Use multi-LLM client
        self.multi_llm = multi_llm_client
        
        self.system_prompt = (
            "You are a meticulous and skeptical Reviewer Agent. Your job is to "
            "critically evaluate a summary based on its content. Assess its reliability, "
            "check for bias, and identify key claims. Be objective and analytical.\n\n"
            "Respond in the following format:\n"
            "RELIABLE: [YES/NO]\n"
            "CRITIQUE: [Your detailed critique]\n"
            "CLAIMS: [List of key claims, separated by commas]"
        )
    
    def _review_with_multi_llm(self, summary: str, url: str):
        """Review using multi-LLM with fallback."""
        logger.info(f"Reviewing summary for URL: {url}")
        
        prompt = f"{self.system_prompt}\n\nPlease review the following summary:\n\nSummary:\n---\n{summary}\n---\nSource URL: {url}"
        
        response = self.multi_llm.generate_with_fallback(prompt, max_tokens=500)
        return self._parse_review_response(response)
    
    def _parse_review_response(self, response_text: str) -> Review:
        """Parse the text response into a Review object."""
        # Default values
        is_reliable = False
        critique = "Unable to parse review response"
        verified_claims = []
        
        try:
            # Extract RELIABLE field
            reliable_match = re.search(r'RELIABLE:\s*(YES|NO)', response_text, re.IGNORECASE)
            if reliable_match:
                is_reliable = reliable_match.group(1).upper() == 'YES'
            
            # Extract CRITIQUE field
            critique_match = re.search(r'CRITIQUE:\s*(.*?)(?=\nCLAIMS:|$)', response_text, re.DOTALL | re.IGNORECASE)
            if critique_match:
                critique = critique_match.group(1).strip()
            
            # Extract CLAIMS field
            claims_match = re.search(r'CLAIMS:\s*(.*?)(?=\n|$)', response_text, re.DOTALL | re.IGNORECASE)
            if claims_match:
                claims_text = claims_match.group(1).strip()
                verified_claims = [claim.strip() for claim in claims_text.split(',') if claim.strip()]
            
        except Exception as e:
            logger.error(f"Error parsing review response: {e}")
            critique = f"Error parsing review: {e}"
        
        return Review(
            critique=critique,
            is_reliable=is_reliable,
            verified_claims=verified_claims
        )
    
    def review(self, summary: str, url: str) -> Review:
        """
        Reviews a summary for bias, reliability, and key claims.
        
        Args:
            summary: The summary generated by the Summarizer Agent.
            url: The source URL for context.
            
        Returns:
            A Review object with the critique and reliability assessment.
        """
        return self._review_with_multi_llm(summary, url)